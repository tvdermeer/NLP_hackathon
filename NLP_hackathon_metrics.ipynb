{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP hackathon testing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Eo7yyrlKmQgW8hVPXtj2JNrRqkLqG2Z5",
      "authorship_tag": "ABX9TyMFgRQCW1WoLkawUyNRdfFU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvdermeer/NLP_hackathon/blob/main/NLP_hackathon_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYV3BbSGR8W4"
      },
      "source": [
        "!pip install transformers datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLGThOU6SJad"
      },
      "source": [
        "from datasets import load_dataset\r\n",
        "dataset= load_dataset('poem_sentiment')\r\n",
        "\r\n",
        "test_set = dataset['test']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8am6DNcSRhK"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\r\n",
        "\r\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/MyDrive/hackathon/nlp/trained_model')\r\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVyfcOe1TmDO"
      },
      "source": [
        "def encode(examples):\r\n",
        "  return tokenizer(examples['verse_text'], truncation=True, padding='max_length')\r\n",
        "\r\n",
        "encoded_test_set = test_set.map(encode, batched=True)\r\n",
        "encoded_test_set = encoded_test_set.map(lambda examples: {'labels': examples['label']}, batched=True)\r\n",
        "\r\n",
        "import torch\r\n",
        "\r\n",
        "encoded_test_set.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\r\n",
        "dataloader = torch.utils.data.DataLoader(encoded_test_set, batch_size=4)\r\n",
        "next(iter(dataloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QkktXqqVx3y"
      },
      "source": [
        "# loading and using metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clI84LKTVw6S"
      },
      "source": [
        "from datasets import load_metric\r\n",
        "\r\n",
        "metric = load_metric('precision')\r\n",
        "\r\n",
        "for batch in dataloader:\r\n",
        "  print(batch)\r\n",
        "  inputs, references = batch\r\n",
        "  predictions = model(inputs)\r\n",
        "  metric.add_batch(predictions= predictions, references= references)\r\n",
        "\r\n",
        "score = metric.compute()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ioq2IctDW864"
      },
      "source": [
        "prediction = model(test_set[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpRzQqwFW_9b"
      },
      "source": [
        "inputs = tokenizer('hello, my dog is cute', return_tensors=\"pt\")\r\n",
        "labels = torch.tensor([1]).unsqueeze(0)\r\n",
        "outputs = model(**inputs, labels = labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTNcWhkzaq1A"
      },
      "source": [
        "x = labels.unsqueeze(0).unsqueeze(0)\r\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19p_v4SobSbZ"
      },
      "source": [
        "inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxsoFYSkbNTM"
      },
      "source": [
        "inputs = {encoded_test_set[0]['input_ids'], encoded_test_set[0]['attention_mask']}\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwtY7Ym8bwj8"
      },
      "source": [
        "test = encoded_test_set[0]\r\n",
        "#labels = test.pop('labels')\r\n",
        "\r\n",
        "outputs = model(**test)\r\n",
        "outputs\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNal-3AigUOc"
      },
      "source": [
        "test"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}