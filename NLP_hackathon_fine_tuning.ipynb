{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP hackathon fine-tuning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1kVdxWPpr6ctnDxZ6+TSw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvdermeer/NLP_hackathon/blob/main/NLP_hackathon_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQgp7si-bFw"
      },
      "source": [
        "# Welcome\r\n",
        "\r\n",
        "This is the notebook that explains how to fine-tune pre-trained models for your downstream task. In other works, train a given model on your task at hand such as summarization, question-answering or POS tagging. \r\n",
        "\r\n",
        "## Use the GPU from Google Colab\r\n",
        "\r\n",
        "We use Colab environments because you can use GPUs freely what certainly speeds up your training and testing of your model. Don't forget to go to 'Runtime' -> 'Change runtime type' and select 'GPU'. \r\n",
        "\r\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YISm4vtf-Mva"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}